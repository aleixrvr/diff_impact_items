{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533e293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, normal, uniform, binomial\n",
    "from numpy import sum, mean, zeros, array, NaN, sqrt, floor\n",
    "import pandas as pd\n",
    "from math import comb\n",
    "from numpy.random import seed\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335c1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9969a",
   "metadata": {},
   "source": [
    "# Bias under different samplig sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec1943",
   "metadata": {},
   "source": [
    "We are going to replicate the `Synthetic Simulation.ipynb` many times to see whether bias disappears increasing the sample size or the number of simultaneous recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82890f63",
   "metadata": {},
   "source": [
    "Values to combine and try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953109d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_n_values = [5, 10, 15]\n",
    "k_prop_values = [0.25, 0.5, 0.75] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701c9b8",
   "metadata": {},
   "source": [
    "Default parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780803cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 2\n",
    "\n",
    "patients_n = 50000\n",
    "sessions_n = 2\n",
    "delta = 0.1\n",
    "exploration_prob = 0.5\n",
    "\n",
    "prob_enthusiast = 0.4\n",
    "enthusiast_effect = 10\n",
    "base_consumption = 0.2\n",
    "inc_enth_cons = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7499df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(items_n, k):\n",
    "    ids = []\n",
    "    sessions = []\n",
    "    patient_types = []\n",
    "    items = []\n",
    "    recommendations = []\n",
    "    consumptions = []\n",
    "    originals = []\n",
    "    explorations = []\n",
    "\n",
    "    items_ids = list(range(items_n))\n",
    "\n",
    "    k_i = 1\n",
    "    k_e = k - 1\n",
    "\n",
    "    for id in range(patients_n):\n",
    "        patient_type = choice([0, 1], size=1, p=[1-prob_enthusiast, prob_enthusiast])[0]\n",
    "        for session in range(sessions_n):\n",
    "            exploration = binomial(1, exploration_prob, size=1)[0]\n",
    "            original = None\n",
    "            if patient_type == 1:\n",
    "                original = items_ids[:k_i] + items_ids[-k_e:]\n",
    "            else:\n",
    "                original = items_ids[:k_e] + items_ids[-k_i:]\n",
    "            if exploration == 1:\n",
    "                recommended = choice(items_ids, size=k, replace=False)\n",
    "            else:\n",
    "                recommended = original\n",
    "\n",
    "            recommended = [int(treat in recommended) for treat in items_ids]     \n",
    "            original = [int(treat in original) for treat in items_ids]     \n",
    "\n",
    "            consumption = []\n",
    "            for treat in range(items_n):\n",
    "                score_assign = base_consumption + inc_enth_cons*patient_type\n",
    "                item_cons = int(uniform(size=1)[0] <= score_assign)\n",
    "                item_cons *= recommended[treat]\n",
    "                consumption.append(item_cons)\n",
    "\n",
    "            ids += [id]*items_n\n",
    "            sessions += [session]*items_n\n",
    "            patient_types += [patient_type]*items_n\n",
    "            items += items_ids\n",
    "            recommendations += recommended\n",
    "            consumptions += consumption\n",
    "            explorations += [exploration]*items_n\n",
    "            originals += original\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': ids,\n",
    "        'session': sessions, \n",
    "        'patient_type': patient_types,\n",
    "        'item': items, \n",
    "        'original': originals,\n",
    "        'recommended': recommendations,\n",
    "        'consumed': consumptions,\n",
    "        'exploration': explorations\n",
    "    })\n",
    "\n",
    "    outcomes = df.groupby('user_id').apply(lambda x: \n",
    "        (sum(x['item']*x['consumed']) + \n",
    "        mean(x['patient_type'])*enthusiast_effect + \n",
    "        normal(size=1, scale=delta))[0]\n",
    "    ).reset_index()\n",
    "    outcomes.rename(columns={0:'outcome'}, inplace = True)\n",
    "    df = df.merge(outcomes, on='user_id')\n",
    "    recs = df.pivot(index=['user_id', 'session', 'exploration'], columns='item', values='recommended').reset_index().merge(outcomes, on='user_id')\n",
    "    originals = df.pivot(index=['user_id', 'session', 'exploration'], columns='item', values='original').reset_index().merge(outcomes, on='user_id')\n",
    "    return(df, recs, originals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919ba7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected(recs, items_n):\n",
    "    expected_diff_items = zeros((items_n, items_n))\n",
    "    expected_compliers = base_consumption*(1-prob_enthusiast) + (base_consumption + inc_enth_cons)*prob_enthusiast\n",
    "    for item_1 in range(items_n):\n",
    "        for item_2 in range(items_n):\n",
    "            expected_diff_items[item_1, item_2] = (item_1 - item_2)*expected_compliers\n",
    "\n",
    "    expected_diff_items = pd.DataFrame(expected_diff_items)\n",
    "    return(expected_diff_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d55992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_direct(recs, items_n):\n",
    "    diff_items_direct = zeros((items_n, items_n))\n",
    "\n",
    "    for item_1 in range(items_n):\n",
    "        for item_2 in range(items_n):\n",
    "            try: \n",
    "                inds_1_0 = recs.loc[:, item_1] == 1\n",
    "                inds_2_0 = recs.loc[:, item_2] == 1\n",
    "                res_1 = recs[inds_1_0].loc[:, 'outcome'].mean() - recs[inds_2_0].loc[:, 'outcome'].mean()\n",
    "            except:\n",
    "                res_1 = NaN\n",
    "            diff_items_direct[item_1, item_2] = res_1\n",
    "\n",
    "    return(pd.DataFrame(diff_items_direct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95487c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_direct_incremental(recs, items_n):\n",
    "    diff_items_direct_inc = zeros((items_n, items_n))\n",
    "\n",
    "    for treat_1 in range(items_n):\n",
    "        for treat_2 in range(items_n):\n",
    "            try: \n",
    "                inds_1_0 = recs.loc[:, treat_1] == 1\n",
    "                inds_2_0 = recs.loc[:, treat_2] == 1\n",
    "                impact_1 = recs[inds_1_0].loc[:, 'outcome'].mean() - recs[~inds_1_0].loc[:, 'outcome'].mean()\n",
    "                impact_2 = recs[inds_2_0].loc[:, 'outcome'].mean() - recs[~inds_2_0].loc[:, 'outcome'].mean()\n",
    "                res_1 = impact_1 - impact_2\n",
    "            except:\n",
    "                res_1 = NaN\n",
    "            diff_items_direct_inc[treat_1, treat_2] = res_1\n",
    "\n",
    "    return(pd.DataFrame(diff_items_direct_inc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9592692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ipw(recs, originals, items_n):\n",
    "    diff_treats_ipw = zeros((items_n, items_n))\n",
    "    items_ids = list(range(items_n))\n",
    "\n",
    "    N = items_n\n",
    "\n",
    "    for treat_1, treat_2 in list(itertools.product(items_ids, items_ids)):\n",
    "\n",
    "        propensity_scores_1 = exploration_prob/N + (1 - exploration_prob)*originals[treat_1]\n",
    "        propensity_scores_2 = exploration_prob/N + (1 - exploration_prob)*originals[treat_2]\n",
    "\n",
    "        # Calculating Adjustment Formula\n",
    "        treat_data = recs.copy()\n",
    "        treat_data['propensity_scores_1'] = exploration_prob/N + (1 - exploration_prob)*originals[treat_1]\n",
    "        treat_data['propensity_scores_2'] = exploration_prob/N + (1 - exploration_prob)*originals[treat_2]\n",
    "\n",
    "        do_1 = 0\n",
    "        for control_vars, sub_data in treat_data.groupby('propensity_scores_1'):\n",
    "            prop = sub_data.shape[0]/treat_data.shape[0]\n",
    "            do_1 += sub_data[sub_data[treat_1] == 1].outcome.mean()*prop\n",
    "\n",
    "        do_2 = 0\n",
    "        for control_vars, sub_data in treat_data.groupby('propensity_scores_2'):\n",
    "            prop = sub_data.shape[0]/treat_data.shape[0]\n",
    "            do_2 += sub_data[sub_data[treat_2] == 1].outcome.mean()*prop\n",
    "\n",
    "        diff_treats_ipw[treat_1, treat_2] = do_1 - do_2\n",
    "\n",
    "    return(pd.DataFrame(diff_treats_ipw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1bc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_differences(df, k, exploration_prob, items_n):\n",
    "\n",
    "    outcomes = df.groupby(['user_id', 'session'], as_index=False).outcome.mean()\n",
    "    recs = df.pivot_table(\n",
    "        index=['user_id', 'session', 'exploration'], \n",
    "        columns='item', values='recommended', fill_value=0). \\\n",
    "        reset_index().merge(outcomes, on='user_id')\n",
    "    originals = df.pivot_table(\n",
    "        index=['user_id', 'session', 'exploration'], \n",
    "        columns='item', values='original', fill_value=0). \\\n",
    "        reset_index().merge(outcomes, on='user_id')\n",
    "\n",
    "    items_ids = df.item.unique()\n",
    "    N = len(items_ids)\n",
    "    diff_items = zeros((N, N))\n",
    "    q = exploration_prob/comb(N-2, k-1)\n",
    "\n",
    "    for item_1 in range(items_n - 1):\n",
    "        for item_2 in range(item_1 + 1, items_n):\n",
    "            other_itemments = [t for t in items_ids if t not in [item_1, item_2]]\n",
    "\n",
    "            # Calculate Propensity Scores\n",
    "            L = recs[other_itemments]*originals[other_itemments]\n",
    "            L += (1 -recs[other_itemments])*(1-originals[other_itemments])\n",
    "            L = (L.apply(sum, axis=1) == N-2).astype(int)\n",
    "            eta = q/(q + L*(1-exploration_prob))\n",
    "            propensity_scores = eta/2 + L*originals[item_1]*(1-eta)\n",
    "\n",
    "            # Calculating Adjustment Formula\n",
    "            inds = recs[item_1] != recs[item_2]\n",
    "            diff_data = recs[inds]\n",
    "            diff_data['propensity_scores'] = propensity_scores[inds]\n",
    "             \n",
    "            do_1 = 0\n",
    "            for control_vars, sub_data in diff_data.groupby('propensity_scores'):\n",
    "                prop = sub_data.shape[0]/diff_data.shape[0]\n",
    "                do_1 += sub_data[sub_data[item_1] == 1].outcome.mean()*prop\n",
    "\n",
    "            do_2 = 0\n",
    "            for control_vars, sub_data in diff_data.groupby('propensity_scores'):\n",
    "                prop = sub_data.shape[0]/diff_data.shape[0]\n",
    "                do_2 += sub_data[sub_data[item_2] == 1].outcome.mean()*prop\n",
    "            \n",
    "            diff_items[item_1, item_2] = do_1 - do_2\n",
    "            diff_items[item_2, item_1] = -(do_1 - do_2)\n",
    "\n",
    "    return(pd.DataFrame(diff_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a6a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_differences(results):\n",
    "    rank = results.iloc[:, 0].copy()\n",
    "    for col in range(1, results.shape[0]):\n",
    "        rank += results.iloc[:, col] - results.iloc[col, 0]\n",
    "    rank /= results.shape[0]\n",
    "    return(rank.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d6f118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(rank_1, rank_2):\n",
    "    rank_1 = pd.DataFrame(rank_1).copy().reset_index()\n",
    "    rank_2 = pd.DataFrame(rank_2).copy().reset_index()\n",
    "    rank_diff = rank_1.merge(rank_2, on='index')\n",
    "    return(sqrt(((rank_diff.iloc[:, 1] - rank_diff.iloc[:, 2])**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b8c85",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc76e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [items_n_values, k_prop_values]\n",
    "combinations = [p for p in product(*list_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805e730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_calcs(combination, exploration_prob):\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    items_n = combination[0]\n",
    "    k_prop = combination[1]\n",
    "    k = int(items_n*k_prop)\n",
    "    df, recs, originals = simulate(items_n, k)\n",
    "\n",
    "    diff_items_method = estimate_differences(df, k, exploration_prob, items_n)\n",
    "    rank_method = rank_differences(diff_items_method)\n",
    "\n",
    "    diff_items_direct = calculate_direct(recs, items_n)\n",
    "    rank_direct = rank_differences(diff_items_direct)\n",
    "    \n",
    "    diff_items_direct_incremental = calculate_direct_incremental(recs, items_n)\n",
    "    rank_direct_incremental = rank_differences(diff_items_direct_incremental)\n",
    "    \n",
    "    diff_items_ipw = calculate_ipw(recs, originals, items_n)\n",
    "    rank_ipw = rank_differences(diff_items_ipw)\n",
    "\n",
    "    diff_items_expected = calculate_expected(recs, items_n)\n",
    "    rank_expected = rank_differences(diff_items_expected)\n",
    "\n",
    "    results = {}\n",
    "    results['rmse_method'] = rmse(rank_method, rank_expected)\n",
    "    results['rmse_direct'] = rmse(rank_direct, rank_expected)\n",
    "    results['rmse_direct_incremental'] = rmse(rank_direct_incremental, rank_expected)\n",
    "    results['rmse_ipw'] = rmse(rank_ipw, rank_expected)\n",
    "    results['items_n_list'] = items_n\n",
    "    results['k_prop_list'] = k_prop\n",
    "    \n",
    "    return(results)\n",
    "    \n",
    "make_calcs_partial = partial(make_calcs, exploration_prob=exploration_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f03a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/9 [00:00<?, ?it/s][Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "100%|████████████████████████████████████████████| 9/9 [22:13<00:00, 148.19s/it]\n"
     ]
    }
   ],
   "source": [
    "results_ = Parallel(n_jobs=n_jobs, verbose=1)\\\n",
    "    (delayed(make_calcs_partial)(comb) for comb in tqdm(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'items_n': [x['items_n_list'] for x in results_],\n",
    "    'k_prop': [x['k_prop_list'] for x in results_],\n",
    "    'ours': [x['rmse_method'] for x in results_],\n",
    "    'direct': [x['rmse_direct'] for x in results_],\n",
    "    'incremental': [x['rmse_direct_incremental'] for x in results_],\n",
    "    'ipw': [x['rmse_ipw'] for x in results_]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c47f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = results.melt(id_vars = ['items_n', 'k_prop'], value_vars = ['ours', 'direct', 'incremental', 'ipw'])\n",
    "results_ = results_.rename(columns={'value': 'RMSE', 'items_n': 'N', 'variable': 'method', 'k_prop': \"k proportion\"})\n",
    "g = sns.FacetGrid(results_, col=\"k proportion\")\n",
    "g.map(sns.lineplot, \"N\", \"RMSE\", 'method').add_legend()\n",
    "plt.ylim(0)\n",
    "plt.savefig('items_n_comparison.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
